{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport numpy as np \nimport pandas as pd\nimport cv2,math,gc\n\nimport torch\nfrom torch.utils.data import DataLoader, Dataset\nfrom torchvision import transforms\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torchvision.models as models\nfrom torch.nn import Parameter\nimport torch.optim as optim\n\n!pip install \"../input/efficient-net/dist/efficientnet_pytorch-0.7.0.tar\"\nfrom efficientnet_pytorch import EfficientNet\n\n!pip install \"../input/faissgpuwheel/faiss_gpu-1.7.0-cp37-cp37m-manylinux2014_x86_64.whl\"\nimport faiss\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nimport cudf, cuml, cupy\nfrom cuml.feature_extraction.text import TfidfVectorizer\nfrom cuml.neighbors import NearestNeighbors\n\nimport warnings\nwarnings.simplefilter('ignore')\n    \ntorch.backends.cudnn.benchmark = True\nfrom transformers import (BertTokenizer, BertModel,\n                          DistilBertTokenizer, DistilBertModel)\nfrom sklearn.preprocessing import LabelEncoder\nfrom tqdm.autonotebook import tqdm","metadata":{"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Processing /kaggle/input/efficient-net/dist/efficientnet_pytorch-0.7.0.tar\nRequirement already satisfied: torch in /opt/conda/lib/python3.7/site-packages (from efficientnet-pytorch==0.7.0) (1.7.0)\nRequirement already satisfied: future in /opt/conda/lib/python3.7/site-packages (from torch->efficientnet-pytorch==0.7.0) (0.18.2)\nRequirement already satisfied: typing_extensions in /opt/conda/lib/python3.7/site-packages (from torch->efficientnet-pytorch==0.7.0) (3.7.4.3)\nRequirement already satisfied: dataclasses in /opt/conda/lib/python3.7/site-packages (from torch->efficientnet-pytorch==0.7.0) (0.6)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from torch->efficientnet-pytorch==0.7.0) (1.19.5)\n\u001b[33mDEPRECATION: Source distribution is being reinstalled despite an installed package having the same name and version as the installed package. pip 21.1 will remove support for this functionality. A possible replacement is use --force-reinstall. You can find discussion regarding this at https://github.com/pypa/pip/issues/8711.\u001b[0m\nBuilding wheels for collected packages: efficientnet-pytorch\n  Building wheel for efficientnet-pytorch (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for efficientnet-pytorch: filename=efficientnet_pytorch-0.7.0-py3-none-any.whl size=16033 sha256=e4f5c2d876a6fc64c04676d5c4091ab9c8902456b948a59001ae4565aa794eb6\n  Stored in directory: /root/.cache/pip/wheels/af/8c/80/1bf8cc2fa471c320978f34c5290675daaa96446e1b9ba45555\nSuccessfully built efficientnet-pytorch\nInstalling collected packages: efficientnet-pytorch\n  Attempting uninstall: efficientnet-pytorch\n    Found existing installation: efficientnet-pytorch 0.7.0\n    Uninstalling efficientnet-pytorch-0.7.0:\n      Successfully uninstalled efficientnet-pytorch-0.7.0\nSuccessfully installed efficientnet-pytorch-0.7.0\nProcessing /kaggle/input/faissgpuwheel/faiss_gpu-1.7.0-cp37-cp37m-manylinux2014_x86_64.whl\nfaiss-gpu is already installed with the same version as the provided wheel. Use --force-reinstall to force an installation of the wheel.\n","output_type":"stream"}]},{"cell_type":"code","source":"TRAIN = False","metadata":{"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"class cfg:\n    img_size = (380,380)\n    feavec_num1 = 512\n    feavec_num2 = 768\n    fea_norm = 64\n    margin = 0.35\n    batch = 16\n    mname = 'efficientnet-b3'\n    clsize = 8812\n    lr = 0.001\n    momentum = 0.9\n    weight_decay = 0.0005\n    log_interval = 1000\n    epochs = 10\n    wpath = '../input/my-weight/efficientnet-b3_eff_bert_arcface_epoch_10.pt'","metadata":{"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"class CFG:\n    DistilBERT = True # if set to False, BERT model will be used\n    bert_hidden_size = 768\n    \n    batch_size = 64\n    epochs = 100\n    num_workers = 4\n    learning_rate = 1e-5 \n    scheduler = \"ReduceLROnPlateau\"\n    step = 'epoch'\n    patience = 2\n    factor = 0.8\n    dropout = 0.5\n    model_path = \"/kaggle/working\"\n    max_length = 30\n    model_save_name = \"bert_model.pt\"\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else 'cpu')","metadata":{"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(\"../input/shopee-product-matching/test.csv\")\n    \ndf_cu = cudf.DataFrame(df)\n\nif len(df)==3:\n    cfg.batch = 3\nprint('df shape is', df.shape )\ndf.head()","metadata":{"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"df shape is (3, 4)\n","output_type":"stream"},{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"        posting_id                                 image       image_phash  \\\n0  test_2255846744  0006c8e5462ae52167402bac1c2e916e.jpg  ecc292392dc7687a   \n1  test_3588702337  0007585c4d0f932859339129f709bfdc.jpg  e9968f60d2699e2c   \n2  test_4015706929  0008377d3662e83ef44e1881af38b879.jpg  ba81c17e3581cabe   \n\n                                               title  \n0  Edufuntoys - CHARACTER PHONE ada lampu dan mus...  \n1  (Beli 1 Free Spatula) Masker Komedo | Blackhea...  \n2   READY Lemonilo Mie instant sehat kuah dan goreng  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>posting_id</th>\n      <th>image</th>\n      <th>image_phash</th>\n      <th>title</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>test_2255846744</td>\n      <td>0006c8e5462ae52167402bac1c2e916e.jpg</td>\n      <td>ecc292392dc7687a</td>\n      <td>Edufuntoys - CHARACTER PHONE ada lampu dan mus...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>test_3588702337</td>\n      <td>0007585c4d0f932859339129f709bfdc.jpg</td>\n      <td>e9968f60d2699e2c</td>\n      <td>(Beli 1 Free Spatula) Masker Komedo | Blackhea...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>test_4015706929</td>\n      <td>0008377d3662e83ef44e1881af38b879.jpg</td>\n      <td>ba81c17e3581cabe</td>\n      <td>READY Lemonilo Mie instant sehat kuah dan goreng</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"if CFG.DistilBERT:\n    model_name='cahya/distilbert-base-indonesian'\n    tokenizer = DistilBertTokenizer.from_pretrained(\"../input/distilbertbaseindonesianfte1\")\n    bert_model = DistilBertModel.from_pretrained(\"../input/distilbertbaseindonesianfte1\")\nelse:\n    model_name='cahya/bert-base-indonesian-522M'\n    tokenizer = BertTokenizer.from_pretrained(model_name)\n    bert_model = BertModel.from_pretrained(model_name)","metadata":{"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"class ArcMarginProduct(nn.Module):\n    def __init__(self, in_features, out_features, s=30.0, m=0.30, easy_margin=False):\n        super(ArcMarginProduct, self).__init__()\n        self.in_features = in_features\n        self.out_features = out_features\n        self.s = s\n        self.m = m\n        self.weight = Parameter(torch.FloatTensor(out_features, in_features))\n        nn.init.xavier_uniform_(self.weight)\n\n        self.easy_margin = easy_margin\n        self.cos_m = math.cos(m)\n        self.sin_m = math.sin(m)\n        self.th = math.cos(math.pi - m)\n        self.mm = math.sin(math.pi - m) * m\n\n    def forward(self, input, label):\n        # --------------------------- cos(theta) & phi(theta) ---------------------------\n        cosine = F.linear(F.normalize(input), F.normalize(self.weight))\n        sine = torch.sqrt((1.0 - torch.pow(cosine, 2)).clamp(0, 1))\n        phi = cosine * self.cos_m - sine * self.sin_m\n        if self.easy_margin:\n            phi = torch.where(cosine > 0, phi, cosine)\n        else:\n            phi = torch.where(cosine > self.th, phi, cosine - self.mm)\n        # --------------------------- convert label to one-hot ---------------------------\n        one_hot = torch.zeros(cosine.size(), device=device)\n        one_hot.scatter_(1, label.view(-1, 1).long(), 1)\n        output = (one_hot * phi) + ((1.0 - one_hot) * cosine)\n        output *= self.s\n        return output  #need softmax then\n\n\nclass Model(nn.Module):\n    def __init__(self,name,clustersize,feavec, bert_model, last_hidden_size=CFG.bert_hidden_size):\n        super(Model, self).__init__()\n        self.eff = EfficientNet.from_name(name)\n        self.bert_model = bert_model\n        self.out = nn.Linear(1000+last_hidden_size,feavec)\n        self.margin = ArcMarginProduct(in_features=feavec, \n                                       out_features = clustersize, \n                                       s=cfg.fea_norm, \n                                       m=cfg.margin)      \n    \n    def get_bert_features(self, batch):\n        output = self.bert_model(input_ids=batch['input_ids'], attention_mask=batch['attention_mask'])\n        last_hidden_state = output.last_hidden_state # shape: (batch_size, seq_length, bert_hidden_dim)\n        CLS_token_state = last_hidden_state[:, 0, :] # obtaining CLS token state which is the first token.\n        return CLS_token_state\n\n    def forward(self, batch, labels=None):\n        x1 = self.eff(batch['image'])\n        x2 = self.get_bert_features(batch)\n        \n        x = torch.hstack((x1, x2))\n        x = self.out(x)\n        if labels is not None:\n            return self.margin(x,labels)\n        return F.normalize(x,dim=1)","metadata":{"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"model = Model(name=cfg.mname,clustersize=cfg.clsize, feavec=512, bert_model=bert_model).to(device)\nmodel.load_state_dict(torch.load(cfg.wpath, map_location=device))","metadata":{"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"<All keys matched successfully>"},"metadata":{}}]},{"cell_type":"code","source":"def load_image(file_name):\n    if TRAIN:\n        file_path = f'/kaggle/input/shopee-product-matching/train_images/{file_name}'\n    else:\n        file_path = f'/kaggle/input/shopee-product-matching/test_images/{file_name}'\n    img = cv2.imread(file_path)\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    img = cv2.resize(img, cfg.img_size)\n    tensor_img = torch.tensor(img)\n    tensor_img = tensor_img.permute(( 2, 0, 1)).float()/255.0\n    return tensor_img","metadata":{"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"class MyDataset(Dataset):\n    def __init__(self, dataframe, tokenizer, mode=\"train\", max_length=None):\n        self.dataframe = dataframe\n        if mode != \"test\":\n            self.targets = dataframe['label'].values\n        texts = list(dataframe['title'].apply(lambda o: str(o)).values)\n        self.encodings = tokenizer(texts, \n                                   padding=True, \n                                   truncation=True, \n                                   max_length=max_length)\n        self.mode = mode\n        self.img = dataframe.image.values\n        \n    def __getitem__(self, idx):\n        # putting each tensor in front of the corresponding key from the tokenizer\n        # HuggingFace tokenizers give you whatever you need to feed to the corresponding model\n        item = {key: torch.tensor(values[idx]) for key, values in self.encodings.items()}\n        # when testing, there are no targets so we won't do the following\n        if self.mode != \"test\":\n            item['labels'] = torch.tensor(self.targets[idx]).long()\n        img = self.img[idx]\n        img = load_image(img)\n        item['image'] = img\n        return item\n    \n    def __len__(self):\n        return len(self.dataframe)","metadata":{"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"def all_embeddings(df):\n    dataset = MyDataset(df, tokenizer, mode='test', max_length=CFG.max_length)\n    loader = DataLoader(dataset,\n                        batch_size=cfg.batch,\n                        shuffle=False,\n                        num_workers=2,\n                        pin_memory=True,\n                        drop_last=False)\n    \n    model.eval()\n    print('start collection')\n    feavec = 512\n    embedded1 = np.empty((0,feavec),dtype='float32')\n    with torch.no_grad():\n        for idx,batch in enumerate(loader):\n            batch = {k: v.to(CFG.device) for k, v in batch.items()}\n            outputs = model(batch)\n            embedded1 = np.append(embedded1, outputs.cpu().detach().numpy(),axis=0)\n\n            if idx%100==0:\n                print(idx,len(loader))\n                print(embedded1.shape)\n    return embedded1","metadata":{"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"def predict_img(df,embeddings,topk=50,threshold=0.63):\n    N,D = embeddings.shape\n    cpu_index = faiss.IndexFlatL2(D)\n    gpu_index = faiss.index_cpu_to_all_gpus(cpu_index)\n    gpu_index.add(embeddings)\n    cluster_distance,cluster_index = gpu_index.search(x=embeddings, k=topk)\n    \n    df['pred_images'] = ''\n    pred = []\n    for k in range(embeddings.shape[0]):\n        idx = np.where(cluster_distance[k,] < threshold)[0]\n        ids = cluster_index[k,idx]\n        #posting_ids = ' '.join(df['posting_id'].iloc[ids].values)\n        posting_ids = df['posting_id'].iloc[ids].values\n        pred.append(posting_ids)\n    df['pred_images'] = pred\n    df['pred_images'] = df.pred_images.apply(lambda x: ' '.join(x))\n    return df","metadata":{"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"all_embeddings1= all_embeddings(df)","metadata":{"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"start collection\n0 1\n(3, 512)\n","output_type":"stream"}]},{"cell_type":"code","source":"df = predict_img(df,all_embeddings1,topk=50,threshold=0.88)\ndf","metadata":{"trusted":true},"execution_count":1,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-d0d91b693a84>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mall_embeddings1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtopk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mthreshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.88\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'predict_img' is not defined"],"ename":"NameError","evalue":"name 'predict_img' is not defined","output_type":"error"}]},{"cell_type":"code","source":"with open('submission.csv', 'w') as outf:\n    print('posting_id,matches', file=outf)\n    for i,(idnum,match) in enumerate(zip(df['posting_id'],df['pred_images'])):\n        print(f'{idnum},{match}', file=outf)","metadata":{"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"df_t = pd.read_csv(\"submission.csv\")\nprint(df_t)","metadata":{"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"        posting_id          matches\n0  test_2255846744  test_2255846744\n1  test_3588702337  test_3588702337\n2  test_4015706929  test_4015706929\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}