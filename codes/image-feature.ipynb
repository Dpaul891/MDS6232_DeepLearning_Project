{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# 1. ResNet","metadata":{}},{"cell_type":"markdown","source":"## $\\bullet$ packages","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nfrom PIL import Image\nfrom torchvision import models, transforms\nimport torch\nimport torch.nn as nn\nimport os\nfrom tqdm import tqdm\nimport gc\n%matplotlib inline\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cuda = torch.cuda.is_available()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## $\\bullet$ path","metadata":{}},{"cell_type":"code","source":"train_image_dir = '../input/shopee-product-matching/train_images'\nfile_list = os.listdir(train_image_dir)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## $\\bullet$ transform images to fixed size 224","metadata":{}},{"cell_type":"code","source":"#transform image to fixed size \ntarget_size = 224\nimage_transform = transforms.Resize(target_size)\n\ndef plt_image(image_name):\n    image = Image.open(train_image_dir + '/' + image_name)\n    image = image_transform(image)\n    #image = np.array(image)\n    #print(\"image_shape: \", image.shape)\n    #plt.imshow(image)\n    #plt.show()\n    image = transforms.ToTensor()(image)\n    return image","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## $\\bullet$ RetNet50","metadata":{}},{"cell_type":"code","source":"class base_resnet(nn.Module):\n    def __init__(self):\n        super(base_resnet, self).__init__()\n        self.model = models.resnet50(pretrained=True)\n    def forward(self, x):\n        x = self.model.conv1(x)\n        x = self.model.bn1(x)\n        x = self.model.relu(x)\n        x = self.model.maxpool(x)\n        x = self.model.layer1(x)\n        x = self.model.layer2(x)\n        x = self.model.layer3(x)\n        x = self.model.layer4(x)\n        x = self.model.avgpool(x)\n\n        return x","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"resnet_model = base_resnet()\nif cuda:\n    resnet_model.cuda()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## $\\bullet$ extract features","metadata":{}},{"cell_type":"code","source":"image_train = []\nfor i in tqdm(range(int(len(file_list)))):\n    image = plt_image(file_list[i])\n    image_train.append(image)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_train = torch.stack(image_train, dim=0)\nif cuda:\n    image_train.cuda()\nimage_feature = resnet_model(image_train)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_feature.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}